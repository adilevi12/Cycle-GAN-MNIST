# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZhUKFOGaf0zIqxBr7pYofJXQYKVH5nqn
"""

import torch.nn as nn
from torchvision.utils import make_grid
import numpy as np

from torch.utils.data import Dataset
import os
import matplotlib.pyplot as plt
import torch

from torchvision import transforms
from torchvision import datasets

ROOT = './data'  

domainA= 'ColoredMNIST_Q2_domainA'
domainB= 'ColoredMNIST_Q2_domainB'
pathA = os.path.join(ROOT, domainA)
pathB = os.path.join(ROOT, domainB)

try:
    os.makedirs(pathA)
except OSError as error:
    pass

try:
    os.makedirs(pathB)
except OSError as error:
    pass

# colored_mnist_dir = os.path.join(ROOT, 'ColoredMNIST_Q2_domainA')

def is_colored_mnist_exists(path):
    """
    Check if coloredMNIST dataset exists in the given directory
    :return: True if exists, False otherwise
    """
    if (os.path.exists(os.path.join(path, 'train.pt')) and os.path.exists(os.path.join(path, 'test.pt'))):
        return True
    return False


def is_pkl_exists(pkl_path):
    """
    Check if pkl file exists in the given directory
    :param pkl_path: path to pkl file
    :return: True if exists, False otherwise
    """
    if os.path.exists(pkl_path):
        return True
    return False


def get_data():
    """
    Get the colored data from the given directory
    :return: train and test data
    """
    # coloredMNIST Dataset domainA
    train_dataset = ColoredMNIST(env='train')
    test_dataset = ColoredMNIST(env='test')
    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=5, shuffle=False)

    # coloredMNIST Dataset domainB
    train_dataset2 = ColoredMNIST(env='train', domainA=False)
    test_dataset2 = ColoredMNIST(env='test', domainA=False)
    train_loader2 = torch.utils.data.DataLoader(dataset=train_dataset2, batch_size=64, shuffle=True)
    test_loader2 = torch.utils.data.DataLoader(dataset=test_dataset2, batch_size=5, shuffle=False)

    return train_loader, test_loader , train_loader2, test_loader2


class ColoredMNIST(datasets.VisionDataset):

    def __init__(self, env='train', transform=None, target_transform=None, domainA=True):
        super(ColoredMNIST, self).__init__(ROOT, transform=transform, target_transform=target_transform)
        self.path = pathA if domainA else pathB
        self.domainA = domainA

        if not is_colored_mnist_exists(self.path):
            self.prepare_colored_mnist()
        if env in ['train', 'test']:
            self.data_label_tuples = torch.load(os.path.join(self.path, env) + '.pt')
        else:
            raise RuntimeError(f'{env} env unknown. Valid envs are train, test')

    def __getitem__(self, index):
        img, target = self.data_label_tuples[index]

        if self.transform is not None:
            img = self.transform(img)
        if self.target_transform is not None:
            target = self.target_transform(target)
        return img, target

    def __len__(self):
        return len(self.data_label_tuples)

    def color_digits_domainA(self,img,label):
        """
        Color the digits in the image
        :param img: image to color
        :return: colored image
        """
        img = img[0]
        h, w = img.shape
        arr = torch.reshape(img, [h, w, 1])

        if label == 0:
            arr = torch.cat((arr, torch.zeros((h, w, 2))), dim=2)
        elif label == 1:
            arr = torch.cat((torch.zeros((h, w, 1)), arr, torch.zeros((h, w, 1))), dim=2)
        elif label == 2:
            arr = torch.cat((torch.zeros((h, w, 2)), arr), dim=2)
        elif label == 3:
            arr = torch.cat((arr, arr, torch.zeros((h, w, 1))), dim=2)
        elif label == 4:
            z = 128/255
            arr = torch.cat((arr*z, torch.zeros((h, w, 1)), arr*z), dim=2)
        elif label == 5:
            g = 165 / 255
            arr = torch.cat((arr, arr*g , torch.zeros((h, w, 1))), dim=2)
        elif label == 6:
            r = 139 / 255
            g = 69 / 255
            b = 19 / 255
            arr = torch.cat((arr * r, arr * g, arr * b), dim=2)
        elif label == 7:
            g = 192 / 255
            b = 203 / 255
            arr = torch.cat((arr, arr*g, arr*b), dim=2)
        elif label == 8:
            arr = torch.cat((torch.zeros((h, w, 1)), arr, arr), dim=2)
        else:
            arr = torch.cat((arr, arr, arr), dim=2)

        arr = arr.permute(2, 0, 1)
        return arr

    def color_digits_domainB(self,img,label):
        """
        Color the digits in the image
        :param img: image to color
        :return: colored image
        """
        img = img[0]
        h, w = img.shape
        arr = torch.reshape(img, [h, w, 1])

        if label == 2:
            arr = torch.cat((arr, torch.zeros((h, w, 2))), dim=2)
        elif label == 3:
            arr = torch.cat((torch.zeros((h, w, 1)), arr, torch.zeros((h, w, 1))), dim=2)
        elif label == 4:
            arr = torch.cat((torch.zeros((h, w, 2)), arr), dim=2)
        elif label == 5:
            arr = torch.cat((arr, arr, torch.zeros((h, w, 1))), dim=2)
        elif label == 6:
            z = 128/255
            arr = torch.cat((arr*z, torch.zeros((h, w, 1)), arr*z), dim=2)
        elif label == 7:
            g = 165 / 255
            arr = torch.cat((arr, arr*g , torch.zeros((h, w, 1))), dim=2)
        elif label == 8:
            r = 139 / 255
            g = 69 / 255
            b = 19 / 255
            arr = torch.cat((arr * r, arr * g, arr * b), dim=2)
        elif label == 9:
            g = 192 / 255
            b = 203 / 255
            arr = torch.cat((arr, arr*g, arr*b), dim=2)
        elif label == 0:
            arr = torch.cat((torch.zeros((h, w, 1)), arr, arr), dim=2)
        else:
            arr = torch.cat((arr, arr, arr), dim=2)

        arr = arr.permute(2, 0, 1)
        return arr

    def prepare_colored_mnist(self):
        """
        Prepare the coloredMNIST dataset
        :return:
        """
        if is_colored_mnist_exists(self.path):
            print('Colored MNIST dataset already exists')

        else:
            print('Preparing Colored MNIST')
            train_mnist = datasets.mnist.MNIST(ROOT, train=True, transform=transforms.ToTensor(), download=True)
            test_mnist = datasets.mnist.MNIST(ROOT, train=False, transform=transforms.ToTensor(), download=True)

            train_set = []
            test_set = []
            if self.domainA:
                for img, label in train_mnist:
                    train_set.append((self.color_digits_domainA(img, label), label))
                for img, label in test_mnist:
                    test_set.append((self.color_digits_domainA(img, label), label))
            else:
                for img, label in train_mnist:
                    train_set.append((self.color_digits_domainB(img, label), label))
                for img, label in test_mnist:
                    test_set.append((self.color_digits_domainB(img, label), label))

            torch.save(train_set, os.path.join(self.path, 'train.pt'))
            torch.save(test_set, os.path.join(self.path, 'test.pt'))


def plot_dataset_digits(dataset, name):
    """
    Plot the dataset digits in color to check it was colored correctly
    :param dataset: colored dataset created by the ColoredMNIST class
    :return:
    """
    fig = plt.figure(figsize=(13, 8))
    columns = 6
    rows = 3
    # ax enables access to manipulate each of subplots
    ax = []

    for i in range(columns * rows):
        img, label = dataset[i]
        img = img.permute(1, 2, 0).detach().numpy()  # convert to numpy array for plotting

        # create subplot and append to ax
        ax.append(fig.add_subplot(rows, columns, i + 1))
        ax[-1].set_title("Label: " + str(label))  # set title for each subplot according to the label
        plt.imshow(img)
    
    fig.suptitle(name, fontsize=20)
    plt.show()

trainA, testA, trainB, testB = get_data()

plot_dataset_digits(trainA.dataset,"Domain A - original images")
plot_dataset_digits(trainB.dataset, "Domain B - transfered images")

def plot_loss(train_loss, name):
    """
    Plot the loss for the train and test set
    :param train_loss: list of train loss for each epoch
    :param test_loss: list of test loss for each epoch
    :param name: name of the model
    """
    plt.plot(train_loss, label='train loss')
    plt.legend()
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.title("{} loss as a function of epoch for the cycleGAN model".format(name))
    plt.show()

class Generator(nn.Module):
    def __init__(self, ):
        super(Generator, self).__init__()
        out_features = 64
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, out_features, kernel_size = 4, stride = 2, padding = 1),
            nn.BatchNorm2d(out_features),
            nn.LeakyReLU(0.2))
        
        self.conv2 = nn.Sequential(
            nn.Conv2d(out_features, out_features*2, kernel_size = 4, stride = 2, padding = 1),
            nn.BatchNorm2d(out_features*2),
            nn.LeakyReLU(0.2))
        
        self.residual1 = nn.Sequential(
            nn.Conv2d(out_features*2, out_features*2, kernel_size = 3, stride = 1, padding = 1),
            nn.BatchNorm2d(out_features*2))

        self.residual2 = nn.Sequential(nn.Conv2d(out_features*2, out_features*2, kernel_size = 3, stride = 1, padding = 1),
            nn.BatchNorm2d(out_features*2),
            nn.LeakyReLU(0.2))
        
        self.deconv1 = nn.Sequential(
            nn.ConvTranspose2d(out_features*2, out_features, kernel_size = 4, stride = 2, padding = 1),
            nn.BatchNorm2d(out_features),
            nn.LeakyReLU(0.2))

        self.deconv2 = nn.Sequential(
            nn.ConvTranspose2d(out_features, 3, kernel_size = 4, stride = 2, padding = 1),
            nn.Tanh())

    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        out = self.residual1(out) + out
        out = self.residual2(out) + out
        out = self.deconv1(out)
        out = self.deconv2(out)
        return out


class Discriminator(nn.Module):
    def __init__(self,conv_dim=64):
        super(Discriminator, self).__init__()
        out_features = 64
        self.conv1 = nn.Sequential(
          nn.Conv2d(3, out_features, kernel_size = 4, stride = 2, padding = 1),
          nn.BatchNorm2d(out_features),
          nn.LeakyReLU(0.2))
        
        self.conv2 = nn.Sequential(
            nn.Conv2d(out_features, out_features*2, kernel_size = 4, stride = 2, padding = 1),
            nn.BatchNorm2d(out_features*2),
            nn.LeakyReLU(0.2))
        
        self.conv3 = nn.Sequential(
            nn.Conv2d(out_features*2, out_features*4, kernel_size = 4, stride = 2, padding = 1),
            nn.BatchNorm2d(out_features*4),
            nn.LeakyReLU(0.2))
        
        self.linear = nn.Sequential(nn.Linear(conv_dim*4*3*3, 1), nn.Sigmoid())

    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        out = self.conv3(out)
        out = out.view(out.size(0), -1)
        out = self.linear(out)
        return out

GA2B = Generator()
GB2A = Generator()
DA = Discriminator()
DB = Discriminator()

criterion_GAN = torch.nn.MSELoss()
criterion_cycle = torch.nn.L1Loss()
criterion_identity = torch.nn.L1Loss()

cuda = torch.cuda.is_available()
print(cuda)

if cuda:
    GA2B = GA2B.cuda()
    GB2A = GB2A.cuda()
    DA = DA.cuda()
    DB = DB.cuda()
    
    criterion_GAN.cuda()
    criterion_cycle.cuda()
    criterion_identity.cuda()

Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor

lr = 0.0002
b1 = 0.5
b2 = 0.999
G_optimizer = torch.optim.Adam(list(GA2B.parameters()) + list(GB2A.parameters()), lr=lr)
D_optimizer = torch.optim.Adam(list(DA.parameters()) + list(DB.parameters()), lr=lr)

def sample_images():
    """show a generated sample from the test set"""
    imgs = next(iter(zip(testA,testB)))
    GA2B.eval()
    GB2A.eval()
    realA = imgs[0][0].type(Tensor)
    fakeB = GA2B(realA).detach()
    realB = imgs[1][0].type(Tensor)
    fakeA = GB2A(realB).detach()

    # Arange images along x-axis
    realA = make_grid(realA, nrow=5, normalize=True)
    fakeB = make_grid(fakeB, nrow=5, normalize=True)
    realB = make_grid(realB, nrow=5, normalize=True)
    fakeA = make_grid(fakeA, nrow=5, normalize=True)

    # Arange images along y-axis
    image_gridA = torch.cat((realA, fakeB), 1)
    image_gridB = torch.cat((realB, fakeA), 1)
    plt.imshow(image_gridA.cpu().permute(1,2,0))
    plt.title('Real A vs Fake B')
    plt.axis('off')
    plt.show()
    plt.imshow(image_gridB.cpu().permute(1,2,0))
    plt.title('Real B vs Fake A')
    plt.axis('off')
    plt.show()

def train_step(realA, realB):
    
    # Set model input
    realA = batchA[0].type(Tensor)
    realB = batchB[0].type(Tensor)

    # Adversarial ground truths
    real = Tensor(np.ones(realA.size(0)))
    fake = Tensor(np.zeros(realA.size(0)))
  

    # ---------------------- Train  Discriminators ----------------------

    # Discriminator Loss
    fakeA = GB2A(realB)
    loss_real = criterion_GAN(DA(realA).squeeze(1), real)
    loss_fake = criterion_GAN(DA(fakeA.detach()).squeeze(1), fake)
    loss_DA = loss_real + loss_fake
    
    fakeB = GA2B(realA)
    loss_real = criterion_GAN(DB(realB).squeeze(1), real)
    loss_fake = criterion_GAN(DB(fakeB.detach()).squeeze(1), fake)
    loss_DB = loss_real + loss_fake
    
    loss_D = loss_DA + loss_DB

    # Backward and optimize
    D_optimizer.zero_grad()
    loss_D.backward()
    D_optimizer.step()


    # ---------------------- Train Genrators ----------------------

    # GAN Loss
    fakeB = GA2B(realA)
    loss_GA2B = criterion_GAN(DB(fakeB).squeeze(1), real)
    fakeA = GB2A(realB)
    loss_GB2A = criterion_GAN(DA(fakeA).squeeze(1), real)
    loss_GAN = loss_GA2B + loss_GB2A

    # Cycle Loss
    recovA = GB2A(fakeB)
    loss_cycleA = criterion_cycle(recovA, realA)
    recovB = GA2B(fakeA)
    loss_cycleB = criterion_cycle(recovB, realB)

    loss_cycle = loss_cycleA + loss_cycleB

    # Total Loss
    loss_GAN = loss_GAN +  loss_cycle
    # Backward and optimize
    G_optimizer.zero_grad()
    loss_GAN.backward()
    G_optimizer.step()
    
    return loss_D, loss_GAN

num_epochs = 100
G_losses = []
D_losses = []

for epoch in range(num_epochs):
    run_loss_G = 0
    run_loss_D = 0
    GB2A.train()
    DA.train()
    GA2B.train()
    DB.train()
    for i, (batchA, batchB) in enumerate(zip(trainA, trainB)):
        realA = batchA[0].type(Tensor)
        realB = batchB[0].type(Tensor)
        loss_D, loss_G = train_step(realA, realB)
        run_loss_D += loss_D.item()
        run_loss_G += loss_G.item()
    print("Epoch: {}/{} \t G loss= {}\t D loss= {}".format(epoch+1, num_epochs, run_loss_G/len(trainA), run_loss_D/len(trainA)))
    sample_images()

    G_losses.append(run_loss_G/len(trainA))
    D_losses.append(run_loss_D / len(trainA))
plot_loss(G_losses, 'Generator')
plot_loss(D_losses, 'Discriminator')

torch.save(GA2B.state_dict(), "GA2B.pkl")
torch.save(GB2A.state_dict(), "GB2A.pkl")
torch.save(DA.state_dict(), "DA.pkl")
torch.save(DB.state_dict(), "DB.pkl")


